{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-allel 1.3.2\n",
      "1.3.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "random.seed(42)\n",
    "import time\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_style('ticks')\n",
    "import bcolz\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import allel; print('scikit-allel', allel.__version__)\n",
    "import scipy\n",
    "\n",
    "# check which version is installed\n",
    "print(allel.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load def\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "import cython\n",
    "\n",
    "def pdiff_int32(np.int32_t[:] x):\n",
    "    cdef:\n",
    "        np.int32_t[:] d\n",
    "        Py_ssize_t i, j, k, n, n_pairs\n",
    "    n = x.shape[0]\n",
    "    n_pairs = (n * (n - 1)) // 2\n",
    "    d = np.empty(n_pairs, dtype='i4')\n",
    "    k = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            d[k] = x[j] - x[i]\n",
    "            k += 1\n",
    "    return np.asarray(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snp_ascertainment(gt, pos, chrom, start, stop, min_maf):\n",
    "    \n",
    "    # SNP ascertainment\n",
    "    ac = gt.count_alleles(max_allele=3)\n",
    "    af = ac.to_frequencies()\n",
    "    loc_asc = (ac.max_allele() == 1) & (af[:, :2].min(axis=1) > min_maf)\n",
    "    loc_region = np.zeros(pos.size, dtype='b1')\n",
    "    loc_region[pos.locate_range(start, stop)] = True\n",
    "    loc_asc &= loc_region\n",
    "    # log('SNP ascertainment', chrom, start, stop, pop, nnz(loc_asc))\n",
    "    print('SNP ascertainment', chrom, start, stop, pop)\n",
    "    \n",
    "    # extract genotypes for population\n",
    "#    popidx = tbl_samples.eq('population', pop).values('index').list()\n",
    "#    gt = gt.subset(variants=loc_asc)\n",
    "    gt = gt.compress(loc_asc, axis=0)\n",
    "    gn = gt.to_n_alt()\n",
    "    \n",
    "    return pos[loc_asc], gn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect LD\n",
    "def collect_ld_distance(pos, gn, n_rep, window_size, window_step=1, permute=False):\n",
    "    assert pos.shape[0] == gn.shape[0]\n",
    "    dist = None\n",
    "    r2 = None\n",
    "    # calculate expected number of data points\n",
    "    expectedlen = ((window_size * (window_size - 1)) // 2) * n_rep\n",
    "    for i in range(n_rep):\n",
    "        # pick a random index\n",
    "        start_index = np.random.randint(0, pos.shape[0]-window_size)\n",
    "        stop_index = start_index + window_size\n",
    "        posr = pos[start_index:stop_index:window_step]\n",
    "#         log(i, start_index, pos[start_index], pos[stop_index])\n",
    "        gnr = gn[start_index:stop_index:window_step]\n",
    "        if permute:\n",
    "            for i in range(window_size//window_step):\n",
    "                gnr[i] = np.roll(gnr[i], i)\n",
    "        x = pdiff_int32(posr)\n",
    "        y = allel.rogers_huff_r(gnr)**2\n",
    "        if dist is None:\n",
    "            dist = bcolz.carray(x, expectedlen=expectedlen)\n",
    "            r2 = bcolz.carray(y, expectedlen=expectedlen)\n",
    "        else:\n",
    "            dist.append(x)\n",
    "            r2.append(y)\n",
    "    return dist[:], r2[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ld_dist(gt, pos, region, pop, min_maf, n_rep, window_size, window_step, permute):\n",
    "    \n",
    "    _, chrom, start, stop = region\n",
    "    \n",
    "    # get genotypes\n",
    "    print(min_maf)\n",
    "    pos, gn = snp_ascertainment(gt, pos, chrom, start, stop, min_maf)\n",
    "    \n",
    "    # collect LD\n",
    "    dist, r2 = collect_ld_distance(pos, gn, n_rep=n_rep, window_size=window_size, window_step=window_step, permute=permute)\n",
    "    \n",
    "    return dist, r2\n",
    "\n",
    "def compute_ld_dist_multi(gt, pos, pop, region, window_sizes, window_steps, n_reps, min_maf):\n",
    "\n",
    "    # accumulate data\n",
    "    dist = None\n",
    "    r2 = None\n",
    "    min_maf = 0.1\n",
    "\n",
    "    for window_size, window_step, n_rep in zip(window_sizes, window_steps, n_reps):\n",
    "        dist_r, r2_r = ld_dist(gt, pos, region, pop, min_maf=0.1, window_size=window_size,window_step=window_step, n_rep=n_rep, permute=False)\n",
    "        if dist is None:\n",
    "            dist = dist_r\n",
    "            r2 = r2_r\n",
    "        else:\n",
    "            # combine\n",
    "            dist = np.concatenate([dist, dist_r])\n",
    "            r2 = np.concatenate([r2, r2_r])\n",
    "            \n",
    "    return dist, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub set gt for a given pop\n",
    "\n",
    "def selectInd(pop, gt):\n",
    "    # locate samples from given population\n",
    "    loc_samples_pop = panel[panel.population == pop].callset_index.values\n",
    "\n",
    "    # create a genotype array of the selected samples\n",
    "    gt_pop = gt.take(loc_samples_pop, axis=1)\n",
    "    return gt_pop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start script\n",
    "\n",
    "zarr_path = '/home/daron/bioInf/wilding/vcf_store/ag1000g.phase2.ar1.pass'\n",
    "callset = zarr.open_group(zarr_path, mode='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom = \"3R\"\n",
    "\n",
    "gt_path = '/'+chrom+'/calldata/GT'\n",
    "gt = allel.GenotypeChunkedArray(callset['/3R/calldata/GT'])\n",
    "\n",
    "pos_path = '/'+chrom+'/samples'\n",
    "pos = allel.SortedIndex(callset['3R/variants/POS'])\n",
    "\n",
    "samples_path = '/'+chrom+'/samples'\n",
    "samples_path = '/'+chrom+'/samples'\n",
    "\n",
    "# load meta file from all pop\n",
    "panel = pd.read_csv(\"/home/daron/bioInf/wilding/ressources/ag1000g.samples.meta.txt\", sep='\\t', usecols=['ox_code', 'population'])\n",
    "\n",
    "# coorespondance of samples order between snp and meta file\n",
    "samples_list = list(callset[samples_path])\n",
    "samples_callset_index = [samples_list.index(s) for s in panel['ox_code']]\n",
    "panel['callset_index'] = samples_callset_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KE\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daron/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in greater\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNP ascertainment 3R 1000000 37000000 KE\n",
      "0.1\n",
      "SNP ascertainment 3R 1000000 37000000 KE\n",
      "0.1\n",
      "SNP ascertainment 3R 1000000 37000000 KE\n",
      "0.1\n",
      "SNP ascertainment 3R 1000000 37000000 KE\n",
      "UGgam\n",
      "0.1\n",
      "SNP ascertainment 3R 1000000 37000000 UGgam\n",
      "0.1\n",
      "SNP ascertainment 3R 1000000 37000000 UGgam\n",
      "0.1\n",
      "SNP ascertainment 3R 1000000 37000000 UGgam\n",
      "0.1\n",
      "SNP ascertainment 3R 1000000 37000000 UGgam\n"
     ]
    }
   ],
   "source": [
    "pop_path = \"/home/daron/bioInf/wilding/vcf_store/pop\"\n",
    "file=open(pop_path, \"r+\")\n",
    "\n",
    "total_df = pd.DataFrame()\n",
    "\n",
    "for pop in file.readlines():\n",
    "    pop = pop.rstrip()\n",
    "    print(pop)\n",
    "    gt_pop = selectInd(pop, gt)\n",
    "    \n",
    "    # Establish baseline via permutation method\n",
    "    perm_baseline = dict()\n",
    "\n",
    "    region = '3R', '3R', 1000000, 37000000\n",
    "    min_maf = .1\n",
    "    n_rep = 500\n",
    "    window_size = 30\n",
    "    window_step = 1\n",
    "    permute = True\n",
    "\n",
    "    dist, r2 = ld_dist(gt_pop, pos, region, pop, min_maf=min_maf, window_size=window_size, window_step=window_step, \n",
    "                       permute=permute, n_rep=n_rep)\n",
    "    # plot_ld_decay(dist, r2, title='%s baseline' % pop)\n",
    "    perm_baseline[pop] = r2\n",
    "    \n",
    "    ### get LD decay\n",
    "    region = '3R', '3R', 1000000, 37000000\n",
    "    window_sizes = (100, 200, 400, 800, 1600, 3200, 6400, 12800, 25600, 51200, 102400, 204800)\n",
    "#    window_sizes = (100, 200, 400)\n",
    "    window_steps = tuple(x//100 for x in window_sizes)\n",
    "    n_reps = (4000, 4000, 4000, 4000, 1000, 1000, 1000, 500, 500, 500, 500, 500, 500)\n",
    "#    n_reps = (4000, 4000, 4000)\n",
    "    min_maf = .1\n",
    "\n",
    "    # get data\n",
    "    dist, r2 = compute_ld_dist_multi(gt_pop, pos, pop, region, window_sizes, window_steps, n_reps, min_maf)\n",
    "    dist = dist[np.isfinite(r2)]\n",
    "    r2 = r2[np.isfinite(r2)]\n",
    "\n",
    "    ### scaled x, y value for ploting\n",
    "    xmax = 14000000\n",
    "    nbin = 400\n",
    "\n",
    "    # apply binning\n",
    "    bins = np.logspace(1, np.log10(xmax), nbin)\n",
    "    s, e, _ = scipy.stats.binned_statistic(dist, r2, statistic=np.nanmean, bins=bins)\n",
    "    x = (e[:-1] + e[1:]) / 2\n",
    "\n",
    "    # adjust for sampling effects\n",
    "    y = s - np.nanmean(perm_baseline[pop])\n",
    "    \n",
    "    # create df\n",
    "    d = {'distance':x,'ld':y}\n",
    "    df = pd.DataFrame(d)\n",
    "    df = df.assign(pop=pop, chrom=chrom)\n",
    "    total_df = pd.concat([total_df, df], axis=0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         distance        ld    pop chrom\n",
      "0    1.018053e+01  0.545784     KE    3R\n",
      "1    1.054810e+01       NaN     KE    3R\n",
      "2    1.092894e+01  0.540039     KE    3R\n",
      "3    1.132353e+01       NaN     KE    3R\n",
      "4    1.173236e+01       NaN     KE    3R\n",
      "..            ...       ...    ...   ...\n",
      "394  1.193656e+07       NaN  UGgam    3R\n",
      "395  1.236753e+07       NaN  UGgam    3R\n",
      "396  1.281406e+07       NaN  UGgam    3R\n",
      "397  1.327671e+07       NaN  UGgam    3R\n",
      "398  1.375607e+07       NaN  UGgam    3R\n",
      "\n",
      "[798 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "### print whole dataset\n",
    "\n",
    "total_df = total_df.dropna()\n",
    "txt_fn = \"/home/daron/bioInf/wilding/popstructure/statDesc/allpop.ld.txt\"\n",
    "total_df.to_csv(txt_fn, sep='\\t', index=False,  float_format='%.8f')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
